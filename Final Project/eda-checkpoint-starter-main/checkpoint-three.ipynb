{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "26037d32-2047-4157-81ef-595916bd66a0"
            },
            "source": [
                "# Checkpoint Three: Cleaning Data\n",
                "\n",
                "Now you are ready to clean your data. Before starting coding, provide the link to your dataset below.\n",
                "\n",
                "My dataset:\n",
                "\n",
                "Import the necessary libraries and create your dataframe(s)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "azdata_cell_guid": "e8adef8e-d0f2-4640-a179-5997f11e82ca"
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(\"./US Natural Disaster Declarations/us_disaster_declarations.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "e172475a-c4ee-414a-8367-9965355dbba6"
            },
            "source": [
                "## Missing Data\n",
                "\n",
                "Test your dataset for missing data and handle it as needed. Make notes in the form of code comments as to your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "azdata_cell_guid": "e1dc66ef-e471-4c27-92e7-ee878c106eba"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Amount of missing data:\n",
                        "[fema_declaration_string]: 0%\n",
                        "[disaster_number]: 0%\n",
                        "[state]: 0%\n",
                        "[declaration_type]: 0%\n",
                        "[declaration_date]: 0%\n",
                        "[fy_declared]: 0%\n",
                        "[incident_type]: 0%\n",
                        "[declaration_title]: 0%\n",
                        "[ih_program_declared]: 0%\n",
                        "[ia_program_declared]: 0%\n",
                        "[pa_program_declared]: 0%\n",
                        "[hm_program_declared]: 0%\n",
                        "[incident_begin_date]: 0%\n",
                        "[incident_end_date]: 0%\n",
                        "[disaster_closeout_date]: 23%\n",
                        "[tribal_request]: 0%\n",
                        "[fips]: 0%\n",
                        "[place_code]: 0%\n",
                        "[designated_area]: 0%\n",
                        "[declaration_request_number]: 0%\n",
                        "[last_ia_filing_date]: 71%\n",
                        "[incident_id]: 0%\n",
                        "[region]: 0%\n",
                        "[designated_incident_types]: 69%\n",
                        "[last_refresh]: 0%\n",
                        "[hash]: 0%\n",
                        "[id]: 0%\n"
                    ]
                }
            ],
            "source": [
                "print(\"Amount of missing data:\")\n",
                "for col in df.columns:\n",
                "    print(f\"[{col}]: \" + str(int(100*df[col].isna().sum()/len(df))) + \"%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fortunately this data is mostly clean, and almost none of the fields with \n",
                "#  missing values are especially relevant to the analysis - mostly \n",
                "#  representing administrative details and disaster response details.\n",
                "# The one field that may have been useful (designated_incident_types) is\n",
                "#  largely redundant in the context of the other classification columns.\n",
                "# https://www.kaggle.com/datasets/headsortails/us-natural-disaster-declarations\n",
                "# A quick check on the source reveals that 'designated_incident_type' is \n",
                "#  mostly redundant and can thus be dropped."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "1233f543-e9a0-4f78-96f5-d7536554102e"
            },
            "source": [
                "## Irregular Data\n",
                "\n",
                "Detect outliers in your dataset and handle them as needed. Use code comments to make notes about your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "efed50ae-16f0-471d-98e2-632553a74c12"
            },
            "outputs": [],
            "source": [
                "# Drop Hurricane Katrina - It represents too far an outlier, especially in regards\n",
                "#  to very specifically disastrous circumstances and ends up blowing out the data.\n",
                "df = df[\n",
                "    ~df['declaration_title'].str.contains('Hurricane Katrina')\n",
                "    ]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "6f5b8ee0-bab3-44bc-958a-67d1e4c0407f"
            },
            "source": [
                "## Unnecessary Data\n",
                "\n",
                "Look for the different types of unnecessary data in your dataset and address it as needed. Make sure to use code comments to illustrate your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {
                "azdata_cell_guid": "e788a239-2fbf-41de-9bd3-19e52e3b187c"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[fema_declaration_string] was not present or likely already removed.\n",
                        "[disaster_number] was not present or likely already removed.\n",
                        "[declaration_date] was not present or likely already removed.\n",
                        "[fy_declared] was not present or likely already removed.\n",
                        "[ia_program_declared] was not present or likely already removed.\n",
                        "[pa_program_declared] was not present or likely already removed.\n",
                        "[hm_program_declared] was not present or likely already removed.\n",
                        "[ih_program_declared] was not present or likely already removed.\n",
                        "[tribal_request] was not present or likely already removed.\n",
                        "[fips] was not present or likely already removed.\n",
                        "[place_code] was not present or likely already removed.\n",
                        "[declaration_request_number] was not present or likely already removed.\n",
                        "[last_ia_filing_date] was not present or likely already removed.\n",
                        "[incident_id] was not present or likely already removed.\n",
                        "[last_refresh] was not present or likely already removed.\n",
                        "[hash] was not present or likely already removed.\n",
                        "[id] was not present or likely already removed.\n",
                        "[designated_area] was not present or likely already removed.\n",
                        "[disaster_closeout_date] was not present or likely already removed.\n",
                        "[designated_incident_types] was not present or likely already removed.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>state</th>\n",
                            "      <th>declaration_type</th>\n",
                            "      <th>incident_type</th>\n",
                            "      <th>declaration_title</th>\n",
                            "      <th>incident_begin_date</th>\n",
                            "      <th>incident_end_date</th>\n",
                            "      <th>region</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>14196</th>\n",
                            "      <td>KY</td>\n",
                            "      <td>DR</td>\n",
                            "      <td>Snowstorm</td>\n",
                            "      <td>Blizzard Of 96</td>\n",
                            "      <td>1996-01-05T00:00:00Z</td>\n",
                            "      <td>1996-01-12T00:00:00Z</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3990</th>\n",
                            "      <td>MN</td>\n",
                            "      <td>DR</td>\n",
                            "      <td>Flood</td>\n",
                            "      <td>Severe Storms &amp; Flooding</td>\n",
                            "      <td>1974-07-13T00:00:00Z</td>\n",
                            "      <td>1974-07-13T00:00:00Z</td>\n",
                            "      <td>5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25147</th>\n",
                            "      <td>AR</td>\n",
                            "      <td>DR</td>\n",
                            "      <td>Severe Storm</td>\n",
                            "      <td>Severe Storms And Flooding</td>\n",
                            "      <td>2004-05-30T00:00:00Z</td>\n",
                            "      <td>2004-07-09T00:00:00Z</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>57349</th>\n",
                            "      <td>AR</td>\n",
                            "      <td>DR</td>\n",
                            "      <td>Biological</td>\n",
                            "      <td>Covid-19 Pandemic</td>\n",
                            "      <td>2020-01-20T00:00:00Z</td>\n",
                            "      <td>2023-05-11T00:00:00Z</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>24460</th>\n",
                            "      <td>PR</td>\n",
                            "      <td>DR</td>\n",
                            "      <td>Severe Storm</td>\n",
                            "      <td>Severe Storms, Flooding, Mudslides, And Landsl...</td>\n",
                            "      <td>2003-11-10T00:00:00Z</td>\n",
                            "      <td>2003-11-23T00:00:00Z</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "      state declaration_type incident_type  \\\n",
                            "14196    KY               DR     Snowstorm   \n",
                            "3990     MN               DR         Flood   \n",
                            "25147    AR               DR  Severe Storm   \n",
                            "57349    AR               DR    Biological   \n",
                            "24460    PR               DR  Severe Storm   \n",
                            "\n",
                            "                                       declaration_title  \\\n",
                            "14196                                     Blizzard Of 96   \n",
                            "3990                            Severe Storms & Flooding   \n",
                            "25147                         Severe Storms And Flooding   \n",
                            "57349                                  Covid-19 Pandemic   \n",
                            "24460  Severe Storms, Flooding, Mudslides, And Landsl...   \n",
                            "\n",
                            "        incident_begin_date     incident_end_date  region  \n",
                            "14196  1996-01-05T00:00:00Z  1996-01-12T00:00:00Z       4  \n",
                            "3990   1974-07-13T00:00:00Z  1974-07-13T00:00:00Z       5  \n",
                            "25147  2004-05-30T00:00:00Z  2004-07-09T00:00:00Z       6  \n",
                            "57349  2020-01-20T00:00:00Z  2023-05-11T00:00:00Z       6  \n",
                            "24460  2003-11-10T00:00:00Z  2003-11-23T00:00:00Z       2  "
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "unnecessary_fields = (\n",
                "    'fema_declaration_string', # Administrative. Drop it.\n",
                "    'disaster_number', # Organizational/Administrative. Drop it.\n",
                "    'declaration_date', # Would only be useful if we were looking administrative-level disaster responses.\n",
                "    'fy_declared', # Similar to above. Primarily administrative and also sometimes unmatched with the actual start date\n",
                "    'ia_program_declared', # Individual Assistance Program - Response type. Dropped.\n",
                "    'pa_program_declared', # Public Assistance Program - Response type. Dropped.\n",
                "    'hm_program_declared', # Hazard Mitigation Program - Response type. Dropped.\n",
                "    'ih_program_declared', # Individuals and Households Program - Response type. Dropped.\n",
                "    'tribal_request', # Marks if request was made by Tribal Nation. Dropped.\n",
                "    'fips', # Administrative. Dropped.\n",
                "    'place_code', # Administrative, would require geospatial processing to make sense of.\n",
                "    'declaration_request_number', # Administrative. Dropped.\n",
                "    'last_ia_filing_date', # Administrative. Dropped.\n",
                "    'incident_id', # Administrative. Dropped.\n",
                "    'last_refresh', # Administrative. Dropped. \n",
                "    'hash', # Organizational. Dropped.\n",
                "    'id', # Organizational. Dropped.\n",
                "    'designated_area', # Too variable of a scope (state/county/reservation/parish/municipio/area/etc.), highly inconsistent formatting, and matching variable dates to geographic coordinates while filtering out similarly named counties in different areas requires a database beyond the resources of this project. Dropped.\n",
                "    'disaster_closeout_date', # Represents administrative response, not actual disaster.\n",
                "    'designated_incident_types', # Seems useful but is redundant to other more specific and filled-out fields\n",
                ")\n",
                "\n",
                "# Main ethos: we're not interested in the response and administrative end of things, the project is more concerned\n",
                "#  with the incident, location, and types of the incidents occurring.\n",
                "\n",
                "for field in unnecessary_fields:\n",
                "    try:\n",
                "        df.drop(field, inplace=True, axis=1)\n",
                "    except:\n",
                "        print(f\"[{field}] was not present or likely already removed.\")\n",
                "\n",
                "df.sample(5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "53e0cf94-c68a-4fa0-9849-9505a66bcce6"
            },
            "source": [
                "## Inconsistent Data\n",
                "\n",
                "Check for inconsistent data and address any that arises. As always, use code comments to illustrate your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {
                "azdata_cell_guid": "e9de6624-812a-43f8-8e20-93b4a49b091f"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "declaration_title\n",
                            "Covid-19 Pandemic               4165\n",
                            "Severe Storms And Flooding      3955\n",
                            "Covid-19                        3692\n",
                            "Severe Storms & Flooding        3387\n",
                            "Severe Winter Storm             2466\n",
                            "                                ... \n",
                            "Typhoon Karen                      1\n",
                            "Abnormally High Tides              1\n",
                            "Co-Wiley Ridge Fire-06/23/02       1\n",
                            "Louisiana Fire                     1\n",
                            "Tornado & Heavy Rainfall           1\n",
                            "Name: count, Length: 2418, dtype: int64"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df['declaration_title'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "incident_type\n",
                            "Severe Storm           19267\n",
                            "Flood                  11204\n",
                            "Hurricane              10823\n",
                            "Biological              7857\n",
                            "Fire                    3843\n",
                            "Snowstorm               3707\n",
                            "Severe Ice Storm        2956\n",
                            "Tornado                 1623\n",
                            "Drought                 1292\n",
                            "Tropical Storm          1059\n",
                            "Coastal Storm            350\n",
                            "Other                    313\n",
                            "Freezing                 301\n",
                            "Earthquake               228\n",
                            "Winter Storm             149\n",
                            "Typhoon                  130\n",
                            "Volcanic Eruption         51\n",
                            "Mud/Landslide             44\n",
                            "Fishing Losses            42\n",
                            "Dam/Levee Break           13\n",
                            "Toxic Substances           9\n",
                            "Chemical                   9\n",
                            "Tsunami                    9\n",
                            "Human Cause                7\n",
                            "Tropical Depression        7\n",
                            "Terrorist                  5\n",
                            "Straight-Line Winds        2\n",
                            "Name: count, dtype: int64"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df['incident_type'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Incident type is clearly the more practical field to hold onto here, \n",
                "#  though for the sake of visualizations, description, and specificity, \n",
                "#  it may be practical to keep the declaration title.\n",
                "# We do absolutely want to keep the incident type, however.\n",
                "# At this point, we can filter and sort the data.\n",
                "weather = (\n",
                "    'Severe Storm',\n",
                "    'Flood',\n",
                "    'Hurricane',\n",
                "    'Fire', \n",
                "    'Snowstorm', \n",
                "    'Severe Ice Storm', \n",
                "    'Tornado', \n",
                "    'Drought', \n",
                "    'Tropical Storm', \n",
                "    'Freezing', \n",
                "    'Winter Storm', \n",
                "    'Typhoon'\n",
                ")\n",
                "dry = (\n",
                "    'Fire',\n",
                "    'Drought'\n",
                ")\n",
                "cold = (\n",
                "    'Severe Ice Storm',\n",
                "    'Winter Storm',\n",
                "    'Snowstorm',\n",
                "    'Freezing'\n",
                ")\n",
                "coastal = (\n",
                "    'Hurricane',\n",
                "    'Tropical Storm',\n",
                "    'Coastal Storm',\n",
                "    'Typhoon',\n",
                "    'Tropical Depression'\n",
                ")\n",
                "climate = df[df['incident_type'].isin(weather)]\n",
                "dry_cli = df[df['incident_type'].isin(dry)]\n",
                "cold_cli = df[df['incident_type'].isin(cold)]\n",
                "coastal_cli = df[df['incident_type'].isin(coastal)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "declaration_title\n",
                            "Severe Storms And Flooding                3948\n",
                            "Severe Storms & Flooding                  3387\n",
                            "Severe Winter Storm                       2466\n",
                            "Severe Storms, Tornadoes, And Flooding    2055\n",
                            "Flooding                                  1540\n",
                            "                                          ... \n",
                            "Or - Winter Fire - 07/15/2002                1\n",
                            "Hurricane Cindy                              1\n",
                            "Drought & Impending Freeze                   1\n",
                            "Or - Eyerly Fire - 07/13/2002                1\n",
                            "Munger Shaw Fire                             1\n",
                            "Name: count, Length: 2336, dtype: int64"
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "climate['declaration_title'].value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Over 2,000 unique values in the 'declaration_title\" field - this suggests that the data would be best cleaned in Excel or similar. The field itself is nearly useless as a field for categorization data due to the per-entry variability and should be understood as more practical for purposes of labeling data points. Even if we did clean the field, it would be mostly redundant on the incident_type."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As an experiment, we can filter for flooding to see how much of the data that represents - if we were able to reduce it so far on just that value, the remaining entries might seem more easy to operate over and it might make more sense to create a flagging field for overlapping incident types."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "45% of climate events had flooding.\n"
                    ]
                }
            ],
            "source": [
                "pct = int(100*(len(climate[climate['declaration_title'].str.contains('Flooding')])/len(climate)))\n",
                "print(f\"{pct}% of climate events had flooding.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's filter for those that didn't."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>state</th>\n",
                            "      <th>declaration_type</th>\n",
                            "      <th>incident_type</th>\n",
                            "      <th>declaration_title</th>\n",
                            "      <th>incident_begin_date</th>\n",
                            "      <th>incident_end_date</th>\n",
                            "      <th>region</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>60003</th>\n",
                            "      <td>AR</td>\n",
                            "      <td>EM</td>\n",
                            "      <td>Hurricane</td>\n",
                            "      <td>Hurricane Laura</td>\n",
                            "      <td>2020-08-26T00:00:00Z</td>\n",
                            "      <td>2020-08-28T00:00:00Z</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>31225</th>\n",
                            "      <td>OK</td>\n",
                            "      <td>DR</td>\n",
                            "      <td>Fire</td>\n",
                            "      <td>Extreme Wildfire Threat</td>\n",
                            "      <td>2005-11-27T00:00:00Z</td>\n",
                            "      <td>2006-03-31T00:00:00Z</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>66836</th>\n",
                            "      <td>FL</td>\n",
                            "      <td>DR</td>\n",
                            "      <td>Hurricane</td>\n",
                            "      <td>Hurricane Helene</td>\n",
                            "      <td>2024-09-23T00:00:00Z</td>\n",
                            "      <td>2024-10-07T00:00:00Z</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5453</th>\n",
                            "      <td>OH</td>\n",
                            "      <td>EM</td>\n",
                            "      <td>Snowstorm</td>\n",
                            "      <td>Snowstorms</td>\n",
                            "      <td>1977-02-02T00:00:00Z</td>\n",
                            "      <td>1977-02-02T00:00:00Z</td>\n",
                            "      <td>5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25947</th>\n",
                            "      <td>PA</td>\n",
                            "      <td>DR</td>\n",
                            "      <td>Hurricane</td>\n",
                            "      <td>Tropical Depression Ivan</td>\n",
                            "      <td>2004-09-17T00:00:00Z</td>\n",
                            "      <td>2004-10-01T00:00:00Z</td>\n",
                            "      <td>3</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2342</th>\n",
                            "      <td>VA</td>\n",
                            "      <td>DR</td>\n",
                            "      <td>Flood</td>\n",
                            "      <td>Tropical Storm Agnes</td>\n",
                            "      <td>1972-06-23T00:00:00Z</td>\n",
                            "      <td>1972-06-23T00:00:00Z</td>\n",
                            "      <td>3</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>23687</th>\n",
                            "      <td>OK</td>\n",
                            "      <td>DR</td>\n",
                            "      <td>Severe Storm</td>\n",
                            "      <td>Severe Storms And Tornadoes</td>\n",
                            "      <td>2003-05-08T00:00:00Z</td>\n",
                            "      <td>2003-05-30T00:00:00Z</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25469</th>\n",
                            "      <td>FL</td>\n",
                            "      <td>DR</td>\n",
                            "      <td>Hurricane</td>\n",
                            "      <td>Hurricane Frances</td>\n",
                            "      <td>2004-09-03T00:00:00Z</td>\n",
                            "      <td>2004-10-08T00:00:00Z</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>66609</th>\n",
                            "      <td>SC</td>\n",
                            "      <td>EM</td>\n",
                            "      <td>Tropical Storm</td>\n",
                            "      <td>Hurricane Helene</td>\n",
                            "      <td>2024-09-25T00:00:00Z</td>\n",
                            "      <td>2024-10-07T00:00:00Z</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>59552</th>\n",
                            "      <td>MT</td>\n",
                            "      <td>FM</td>\n",
                            "      <td>Fire</td>\n",
                            "      <td>Falling Star Fire</td>\n",
                            "      <td>2020-08-02T00:00:00Z</td>\n",
                            "      <td>2020-08-04T00:00:00Z</td>\n",
                            "      <td>8</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "      state declaration_type   incident_type            declaration_title  \\\n",
                            "60003    AR               EM       Hurricane              Hurricane Laura   \n",
                            "31225    OK               DR            Fire      Extreme Wildfire Threat   \n",
                            "66836    FL               DR       Hurricane             Hurricane Helene   \n",
                            "5453     OH               EM       Snowstorm                   Snowstorms   \n",
                            "25947    PA               DR       Hurricane     Tropical Depression Ivan   \n",
                            "2342     VA               DR           Flood         Tropical Storm Agnes   \n",
                            "23687    OK               DR    Severe Storm  Severe Storms And Tornadoes   \n",
                            "25469    FL               DR       Hurricane            Hurricane Frances   \n",
                            "66609    SC               EM  Tropical Storm             Hurricane Helene   \n",
                            "59552    MT               FM            Fire            Falling Star Fire   \n",
                            "\n",
                            "        incident_begin_date     incident_end_date  region  \n",
                            "60003  2020-08-26T00:00:00Z  2020-08-28T00:00:00Z       6  \n",
                            "31225  2005-11-27T00:00:00Z  2006-03-31T00:00:00Z       6  \n",
                            "66836  2024-09-23T00:00:00Z  2024-10-07T00:00:00Z       4  \n",
                            "5453   1977-02-02T00:00:00Z  1977-02-02T00:00:00Z       5  \n",
                            "25947  2004-09-17T00:00:00Z  2004-10-01T00:00:00Z       3  \n",
                            "2342   1972-06-23T00:00:00Z  1972-06-23T00:00:00Z       3  \n",
                            "23687  2003-05-08T00:00:00Z  2003-05-30T00:00:00Z       6  \n",
                            "25469  2004-09-03T00:00:00Z  2004-10-08T00:00:00Z       4  \n",
                            "66609  2024-09-25T00:00:00Z  2024-10-07T00:00:00Z       4  \n",
                            "59552  2020-08-02T00:00:00Z  2020-08-04T00:00:00Z       8  "
                        ]
                    },
                    "execution_count": 39,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "climate[~climate['declaration_title'].str.contains('Flooding')].sample(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "declaration_title\n",
                            "Severe Winter Storm           2466\n",
                            "Severe Winter Storms          1375\n",
                            "Drought                       1014\n",
                            "Wildfires                      700\n",
                            "Hurricane Irma                 663\n",
                            "                              ... \n",
                            "Hurricane Cindy                  1\n",
                            "Drought & Impending Freeze       1\n",
                            "Hurricane Cleo                   1\n",
                            "Hurricane Hilda                  1\n",
                            "Typhoon Louise                   1\n",
                            "Name: count, Length: 1971, dtype: int64"
                        ]
                    },
                    "execution_count": 46,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "climate[~climate['declaration_title'].str.contains('Flood')]['declaration_title'].value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "2007 unique values remaining after we filter out one of the most common items is still entirely impractical to hand-filter and sort each case in Python. At this point, if we wanted to follow through with something like that (which would be a largely redundant process), it would make the most sense to take it into Excel or to create additional calculated fields in the upcoming visualization with a boolean flag on whether an event matches one or multiple criteria if we wanted to be more specific with the types of events occurring. I.e. - something like flooding doesn't occur on its own, requiring causes like rain or dam breaks, or in the case of fire, a dry climate, a trigger event, etc. All this to say - we could keep the field and use it to split and visualize a shift in the nature of disasters if we wanted."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "dedc0bfe-17d0-40b2-914f-2ddb54f9ce0d"
            },
            "source": [
                "## Summarize Your Results\n",
                "\n",
                "Make note of your answers to the following questions.\n",
                "\n",
                "1. Did you find all four types of dirty data in your dataset?\n",
                "\n",
                "    No - the data was remarkably clean overall, and the few fields that could have contained dirty results were dropped ('designated_area') due to too variable of scope - ranged from state-wide to county level and a range of other response types. While I didn't see any typos on a cursory glance of the column, actually matching those to coordinates and scopes in a geospatial database (we could easily search and match for many by simply concatenating state of declaration with the designated area) is a task beyond the scope of the project and for fairly minimal returns.\n",
                "\n",
                "    The data had no discovered duplicates, as revealed in checkpoint 2.\n",
                "    \n",
                "    There are a few fields (declaration_title) where the output does get a bit messy and inconsistent, including unnecessary quotation marks, vague entries, and vague/specific entries that are either redundant to incident_type or specific to the point of uselessness beyond perhaps labeling outlier events. Some of the entries did seem to have messy input (something automated) as well, and contain examples like:\n",
                "\n",
                "    \"Severe Storms, Tornadoes, Straight-Line Winds, And\"\n",
                "\n",
                "    The designated_area field would require case-by-case analysis on many of the entries - e.g. a reservation could be labeled something like:\n",
                "\n",
                "    Alamo Navajo (Indian Reservation)\n",
                "\n",
                "    Jicharilla Apache Indian Reservation\n",
                "\n",
                "    San Felipe/Santa Ana Joint Area\n",
                "\n",
                "    etc.\n",
                "    \n",
                "    The geographic specificity is largely beyond the scope of the project, especially when we are looking at regional patterns down to roughly the state level at finest resolution.\n",
                "\n",
                "\n",
                "2. Did the process of cleaning your data give you new insights into your dataset?\n",
                "\n",
                "    No and yes - no, because I did very similar work in the previous checkpoint in order to visualize and organize the data to better understand it, including breaking it down into the subsections. Additionally, much of the data is as-expected, almost alarmingly so, including the increases in declarations and eventful versus non-eventful years. Yes, because that work - especially the visualization and value counts - showed remarkable outliers like Katrina, but also allowed a better understanding into the entry processes of the data (though it was remarkably clean, save for a few fields)\n",
                "\n",
                "3. Is there anything you would like to make note of when it comes to manipulating the data and making visualizations?\n",
                "\n",
                "    For dates and times, field of interest is generally 'incident_begin_date' though we can keep 'incident_end_date' for visualization if we want later.\n",
                "\n",
                "    Incident type is the most useful field to sort on.\n",
                "\n",
                "    The other fields (state/region) can help give clarity to where incidents are occurring.\n",
                "\n",
                "    Due to the nature of the dataset, the information is generally limited in scale to types of events, dates, and locations. The finest scale we can analyze or visualize is state-level, though regional results are also interesting and may prove more practical for actual analysis. We could, for example, create a visualization of drought-prone states in the West, colder states in the North versus states in the plains more likely to face windy weather, low ground-level states in the South more likely to face tropical storms and flooding, etc. - FEMA already has these defined in the dataset, though it may be good to give them a once-over, e.g. excluding certain areas for the sake of not skewing analysis (e.g. DC is too specific, Hawaii is grouped with California but will have different climate patterns, etc.). \n",
                "    \n",
                "    If we wanted, we could possibly utilize the program declaration fields as a barometer of event severity or response, though these seem to fluctuate in actual application, practicality, etc.\n",
                "\n",
                "    Since we are working on Type/Location/Date, it may be helpful to bring in another dataset to add an extra dimension to the analysis, or to use calculated fields to help develop more nuanced visualizations and analysis.\n",
                "\n",
                "    To the ends of added datasets, the data could not be about the events themselves. Adding such a dataset would be redundant and create an unreasonable time-suck for the project late in the process and would inevitably have thousands of missing and unmatched fields, even if it could offer an extra dimension (event severity/casualties, etc.). Therefore, the only additional datasets we can rely on should be geographic and chronological. Geographic datasets could represent changes in population in states/regions over the years (a simple census pull), yearly temperatures, El Nino/La Nina years, and so on. If we find the visualizations aren't as informative or interesting as desired, it may be practical to add these supplemental datasets in.\n",
                "\n",
                "\n",
                "\n",
                "    "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
